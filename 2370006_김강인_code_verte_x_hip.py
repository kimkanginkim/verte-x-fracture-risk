# -*- coding: utf-8 -*-
"""2370006_김강인_code_VERTE-X_hip.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14biiLmYmK4GyFYKIr0wkmmySKKlZqoPv
"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.neural_network import MLPRegressor
from sklearn.metrics import mean_squared_error, r2_score

############## 학생 정보 입력 필수! ##############
student_id = "2370006"  # 학생 ID
student_name = "김강인"  # 학생 이름
############## 학생 정보 입력 필수! ##############

############## Train 데이터 로드 및 전처리 (자유롭게 수정) ##############
# 데이터 로드
data = pd.read_csv('train.csv')
X = data.drop(columns=['frax_hip_fracture'])  # 'frax_hip_fracture'은 타겟 변수로 가정
y = data['frax_hip_fracture']

# 결측치 처리
X.fillna(X.mean(), inplace=True)  # 수치형 변수의 결측치를 평균값으로 대체

# 범주형 변수 처리
X = pd.get_dummies(X, drop_first=True)  # 범주형 변수를 더미 변수로 변환

# Train-Test Split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=5758)

# 스케일링 (StandardScaler 사용)
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# 특성 중요도 기반 선택
# RandomForestRegressor를 사용해 특성 중요도 계산
rf = RandomForestRegressor(random_state=5758)
rf.fit(X_train, y_train)
importances = rf.feature_importances_

# 상위 10개의 중요한 특성 선택
importance_threshold = sorted(importances, reverse=True)[10]  # 상위 10개 값 기준
selected_features = [X.columns[i] for i, imp in enumerate(importances) if imp >= importance_threshold]

# 선택된 특성만 사용
X_train = pd.DataFrame(X_train, columns=X.columns)[selected_features]
X_test = pd.DataFrame(X_test, columns=X.columns)[selected_features]
############## Train 데이터 로드 및 전처리 (자유롭게 수정) ##############

############## 모델 선언 및 학습 (모델 자유롭게 수정) ##############
models = {
    'GradientBoostingRegressor': GradientBoostingRegressor(random_state=5758),
    'MLPRegressor': MLPRegressor(hidden_layer_sizes=(100,), max_iter=500, random_state=5758),
    'RandomForestRegressor': RandomForestRegressor(random_state=5758),
}
############## 모델 선언 및 학습 (모델 자유롭게 수정) ##############

############## 내부 테스트 데이터로 평가 ##############
# 모델 학습 및 내부 테스트 데이터 평가
best_model = None
best_r2 = float('-inf')  # R² 기준으로 최고 성능 모델을 선택
best_mse = None  # 최고 성능 모델의 MSE 저장
results = []

for name, model in models.items():
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    r2 = r2_score(y_test, y_pred)
    mse = mean_squared_error(y_test, y_pred)
    results.append({'Model': name, 'MSE': mse, 'R^2': r2})

    # 최고 성능 모델 선택
    if r2 > best_r2:
        model = model
        best_r2 = r2
        best_mse = mse

# 성능 결과 출력
results_df = pd.DataFrame(results)
print("모델 성능 비교:")
print(results_df)

# 출력
print("Best Model R-squared (R²):", best_r2)
print("Best Model Mean Squared Error (MSE):", best_mse)
############## 내부 테스트 데이터로 평가 ##############

############## Unseen Test 데이터 로드 ##############
test_data = pd.read_csv('test.csv')
X_test_ext = test_data.drop(columns=['id'])  # 'id' 열은 식별자로 가정
############## Unseen Test 데이터 로드 ##############

############## Train 데이터 전처리 코드 적용 ##############
# Test 데이터에 Train 데이터의 더미 구조를 적용
X_test_ext = pd.get_dummies(X_test_ext, drop_first=True)
X_test_ext = X_test_ext.reindex(columns=X.columns, fill_value=0)
X_test_ext = scaler.transform(X_test_ext)  # 동일한 스케일러를 외부 테스트 데이터에 적용
X_test_ext = pd.DataFrame(X_test_ext, columns=X.columns)[selected_features]
############## Train 데이터 전처리 코드 적용 ##############

############## Test 데이터에 예측 수행 (코드 수정 X) ##############
test_predictions = model.predict(X_test_ext)

# 예측 결과 저장
test_data['prediction'] = test_predictions
output_filename = f"{student_id}_{student_name}_predictions.csv"  # 파일명 생성
test_data[['id', 'prediction']].to_csv(output_filename, index=False)

print(f"Predictions saved to '{output_filename}'")
############## Test 데이터에 예측 수행 ##############